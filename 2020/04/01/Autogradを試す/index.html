<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-161733173-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-161733173-1');
</script>
<!-- End Google Analytics -->

  
  <title>Autogradを試す | Infer our lives with data</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="お仕事でpytorchを使うって言うので、個人的なメモのその１．環境として  pythonは3.7 pytorchは1.4.0環境はセットアップされた前提だとします。  AutoGradについて123456## まずはimportimport torch## Tensorを作りますtensor1 &#x3D; torch.Tensor([[1,2,3], [4,5,6]])tensor2 &#x3D; torch.T">
<meta property="og:type" content="article">
<meta property="og:title" content="Autogradを試す">
<meta property="og:url" content="https://kyoro1.github.io/2020/04/01/Autograd%E3%82%92%E8%A9%A6%E3%81%99/index.html">
<meta property="og:site_name" content="Infer our lives with data">
<meta property="og:description" content="お仕事でpytorchを使うって言うので、個人的なメモのその１．環境として  pythonは3.7 pytorchは1.4.0環境はセットアップされた前提だとします。  AutoGradについて123456## まずはimportimport torch## Tensorを作りますtensor1 &#x3D; torch.Tensor([[1,2,3], [4,5,6]])tensor2 &#x3D; torch.T">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2020-04-01T13:33:52.000Z">
<meta property="article:modified_time" content="2020-04-06T14:22:58.803Z">
<meta property="article:author" content="Kyoichi Iwasaki">
<meta property="article:tag" content="pytorch">
<meta property="article:tag" content="data science">
<meta name="twitter:card" content="summary">
<meta name="twitter:creator" content="@kyoro1">
  
    <link rel="alternate" href="/atom.xml" title="Infer our lives with data" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 4.2.0"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Infer our lives with data</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">topics around data science</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="https://kyoro1.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Autogradを試す" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2020/04/01/Autograd%E3%82%92%E8%A9%A6%E3%81%99/" class="article-date">
  <time class="dt-published" datetime="2020-04-01T13:33:52.000Z" itemprop="datePublished">2020-04-01</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      Autogradを試す
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>お仕事で<code>pytorch</code>を使うって言うので、個人的なメモのその１．環境として</p>
<ul>
<li>pythonは3.7</li>
<li>pytorchは1.4.0<br>環境はセットアップされた前提だとします。</li>
</ul>
<h2 id="AutoGradについて"><a href="#AutoGradについて" class="headerlink" title="AutoGradについて"></a><code>AutoGrad</code>について</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## まずはimport</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="comment">## Tensorを作ります</span></span><br><span class="line">tensor1 = torch.Tensor([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>], [<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]])</span><br><span class="line">tensor2 = torch.Tensor([[<span class="number">7</span>,<span class="number">8</span>,<span class="number">9</span>], [<span class="number">10</span>,<span class="number">11</span>,<span class="number">12</span>]])</span><br></pre></td></tr></table></figure>
<p>後々のために数式で書いておきましょうか。</p>
<iframe src="https://rcm-fe.amazon-adsystem.com/e/cm?o=9&p=48&l=ur1&category=foodbeverage&f=ifr&linkID=f4fb4deb0a6a79bf9e547780bdcc8627&t=languagenoteb-22&tracking_id=languagenoteb-22" width="728" height="90" scrolling="no" border="0" marginwidth="0" style="border:none;" frameborder="0"></iframe>

<a id="more"></a>
<script type="math/tex; mode=display">tensor1 = (a_{ij}), tensor2 = (b_{kl})</script><p>例えば、 <script type="math/tex">a_{11} = 1, b_{12}=8</script> などです。</p>
<p>で、この後自動微分(<code>AutoGrad</code>)を勝手にやってもらうためのオマジナイ（と言ったら怒られるかな）の<code>requires_grad</code>に対応してるか、をこの状態でチェックしてみます。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor1.requires_grad <span class="comment">## False tensor2も同様ですね。</span></span><br></pre></td></tr></table></figure>
<p>どうやってこれを<code>True</code>にするか、と言うと、ほんの少し異なる<code>requires_grad_()</code>を使います：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor1.requires_grad_()</span><br><span class="line"><span class="comment">##tensor([[1., 2., 3.],</span></span><br><span class="line"><span class="comment">##        [4., 5., 6.]], requires_grad=True)</span></span><br><span class="line">tensor1.requires_grad </span><br><span class="line"><span class="comment">## Trueになると思います。</span></span><br></pre></td></tr></table></figure>
<p>一足早いですが、gradient(Neural Networkのパラメータを調整時に求める勾配)があるかって言うとまだないですね：<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor1.grad</span><br><span class="line"><span class="comment">## None</span></span><br></pre></td></tr></table></figure></p>
<p>で、足し算してみますね：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">output_tensor = tensor1 + tensor2</span><br><span class="line">output_tensor.backward()</span><br></pre></td></tr></table></figure>
<p>とやると、盛大に怒られます。取り敢えず、アウトプットをスカラー(1次元の数)にせよ、と。</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">---------------------------------------------------------------------------</span><br><span class="line">RuntimeError                              Traceback (most recent call last)</span><br><span class="line"> <span class="keyword">in</span> </span><br><span class="line">----&gt; 1 output_tensor.backward()</span><br><span class="line"></span><br><span class="line">~\AppData\Local\Continuum\anaconda3\lib\site-packages\torch\tensor.py <span class="keyword">in</span> backward(self, gradient, retain_graph, create_graph)</span><br><span class="line">    <span class="number">193</span>                 products. Defaults to ``<span class="literal">False</span>``.</span><br><span class="line">    <span class="number">194</span>         <span class="string">"""</span></span><br><span class="line"><span class="string">--&gt; 195         torch.autograd.backward(self, gradient, retain_graph, create_graph)</span></span><br><span class="line"><span class="string">    196 </span></span><br><span class="line"><span class="string">    197     def register_hook(self, hook):</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">~\AppData\Local\Continuum\anaconda3\lib\site-packages\torch\autograd\__init__.py in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables)</span></span><br><span class="line"><span class="string">     91         grad_tensors = list(grad_tensors)</span></span><br><span class="line"><span class="string">     92 </span></span><br><span class="line"><span class="string">---&gt; 93     grad_tensors = _make_grads(tensors, grad_tensors)</span></span><br><span class="line"><span class="string">     94     if retain_graph is None:</span></span><br><span class="line"><span class="string">     95         retain_graph = create_graph</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">~\AppData\Local\Continuum\anaconda3\lib\site-packages\torch\autograd\__init__.py in _make_grads(outputs, grads)</span></span><br><span class="line"><span class="string">     32             if out.requires_grad:</span></span><br><span class="line"><span class="string">     33                 if out.numel() != 1:</span></span><br><span class="line"><span class="string">---&gt; 34                     raise RuntimeError("grad can be implicitly created only for scalar outputs")</span></span><br><span class="line"><span class="string">     35                 new_grads.append(torch.ones_like(out, memory_format=torch.preserve_format))</span></span><br><span class="line"><span class="string">     36             else:</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">RuntimeError: grad can be implicitly created only for scalar outputs</span></span><br></pre></td></tr></table></figure>
<p>ということで、計算式をちょっと変えます</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">output_tensor = (tensor1 * tensor2).mean()</span><br></pre></td></tr></table></figure>
<p>冒頭の式</p>
<script type="math/tex; mode=display">tensor1 = (a_{ij}), tensor2 = (b_{kl})</script><p>の記号を使うと、、、</p>
<script type="math/tex; mode=display">output\_tensor = \frac{1}{6}\times(\sum_{i, j}a_{ij}b_{ij})</script><p>ですね（対応する行列成分を掛け算した結果に対して、最後に平均を取る）。ここでもう一度<code>backward</code>を取ってみます。パット見は何も返って来ません（それが正常です）：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">output_tensor.backward()</span><br></pre></td></tr></table></figure>
<p>この後に<code>.grad</code>を計算させると、、、</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tensor1.grad</span><br><span class="line"><span class="comment">##tensor([[1.1667, 1.3333, 1.5000],</span></span><br><span class="line"><span class="comment">##        [1.6667, 1.8333, 2.0000]])</span></span><br></pre></td></tr></table></figure>
<p>ですが、これが出てきた背景をば。結論から言えば、<code>tensor1</code>の各成分<script type="math/tex">(a_{ij})</script>に関する偏微分(partial)</p>
<script type="math/tex; mode=display">\frac{\partial}{\partial a_{ij}}output\_tensor</script><p>を計算しています。上記のように<code>output_tensor</code>は</p>
<script type="math/tex; mode=display">output\_tensor = \frac{1}{6}\times(\sum_{i, j}a_{ij}b_{ij})</script><p>でしたから、例えば <script type="math/tex">a_{11}</script> に関して(偏)微分すると、</p>
<script type="math/tex; mode=display">
\frac{\partial}{\partial a_{11}}output\_tensor = \frac{1}{6}\times b_{11}=\frac{7}{6} = 1.166..</script><p>となり一致しました。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="https://kyoro1.github.io/2020/04/01/Autograd%E3%82%92%E8%A9%A6%E3%81%99/" data-id="ck8impd3k0000r8slg60n3u4i" data-title="Autogradを試す" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/data-science/" rel="tag">data science</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/pytorch/" rel="tag">pytorch</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2020/04/02/Pytorch%E3%81%A7%E5%8D%98%E5%9B%9E%E5%B8%B0%E3%82%84%E3%81%A3%E3%81%A6%E3%81%BF%E3%82%8B/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Pytorchで単回帰やってみる
        
      </div>
    </a>
  
  
    <a href="/2020/03/25/pmi-acp/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">pmi-acp</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Poisson-distribution/" style="font-size: 10px;">Poisson distribution</a> <a href="/tags/binominal-distribution/" style="font-size: 10px;">binominal distribution</a> <a href="/tags/data-science/" style="font-size: 20px;">data science</a> <a href="/tags/janome/" style="font-size: 10px;">janome</a> <a href="/tags/logistic-regression/" style="font-size: 10px;">logistic regression</a> <a href="/tags/matplotlib/" style="font-size: 10px;">matplotlib</a> <a href="/tags/multi-class-classification/" style="font-size: 10px;">multi-class classification</a> <a href="/tags/pandas/" style="font-size: 10px;">pandas</a> <a href="/tags/pmi-acp/" style="font-size: 10px;">pmi-acp</a> <a href="/tags/python/" style="font-size: 15px;">python</a> <a href="/tags/pytorch/" style="font-size: 20px;">pytorch</a> <a href="/tags/restore-extraction/" style="font-size: 10px;">restore extraction</a> <a href="/tags/self-introduction/" style="font-size: 10px;">self introduction</a> <a href="/tags/simple-regression/" style="font-size: 10px;">simple regression</a> <a href="/tags/site-maintenance/" style="font-size: 10px;">site maintenance</a> <a href="/tags/wordcloud/" style="font-size: 10px;">wordcloud</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/04/">April 2020</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/03/">March 2020</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2020/04/06/%E5%87%BA%E7%8F%BE%E7%A2%BA%E7%8E%871-%E3%81%AE%E3%81%8A%E3%81%BF%E3%81%8F%E3%81%98%E3%82%92100%E5%9B%9E%E9%80%A3%E7%B6%9A%E5%BC%95%E3%81%91%E3%81%B0%E3%80%811%E5%9B%9E%E3%81%AF%E5%BD%93%E3%81%9F%E3%82%8B%EF%BC%9F/">出現確率1%のおみくじを100回連続引けば、1回は当たる？</a>
          </li>
        
          <li>
            <a href="/2020/04/06/Cloud%E3%81%8C%E4%BD%9C%E3%82%8A%E3%81%9F%E3%81%8F%E3%81%AA%E3%81%A3%E3%81%9F%E3%82%89%E3%80%82/">Word Cloudが作りたくなったら。</a>
          </li>
        
          <li>
            <a href="/2020/04/04/Pytorch%E3%81%A7logistic%E5%9B%9E%E5%B8%B0%E3%82%92%E3%82%84%E3%81%A3%E3%81%A6%E3%81%BF%E3%82%8B/">pytorchでlogistic回帰をやってみる</a>
          </li>
        
          <li>
            <a href="/2020/04/02/Pytorch%E3%81%A7%E5%8D%98%E5%9B%9E%E5%B8%B0%E3%82%84%E3%81%A3%E3%81%A6%E3%81%BF%E3%82%8B/">Pytorchで単回帰やってみる</a>
          </li>
        
          <li>
            <a href="/2020/04/01/Autograd%E3%82%92%E8%A9%A6%E3%81%99/">Autogradを試す</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2020 Kyoichi Iwasaki<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>